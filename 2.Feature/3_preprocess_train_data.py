import os
import re
import jpype
import pandas as pd
from konlpy.tag import Okt

# ğŸ”¹ **Okt ê°ì²´ ìƒì„±**
okt = Okt()

# ğŸ”¹ **ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ (ì¤‘ìš” í‚¤ì›Œë“œëŠ” í¬í•¨ X)**
stop_words = ["ë°", "ë“±", "ì´ìƒ", "ì´í•˜", "ëŒ€í•œ", "ê²½ìš°", "ì œ", "ê·¸", "ì´", "ì €", "ì´ëŸ°", "ì €ëŸ°", "ê°ì¢…",
              "í•˜ëŠ”", "í•˜ëŠ”ê²ƒ", "í• ", "í•˜ê³ ", "í•œë‹¤", "í•œ", "ë˜ì–´", "ë˜ë©°", "í•˜ëŠ”ë°", "í•˜ëŠ”ì§€", "í•˜ê²Œ", "í•˜ë©´", "í•˜ë©´ì„œ",
              "ìˆ˜", "ìˆë‹¤", "ì—†ëŠ”", "ìˆìœ¼ë©°", "ìˆì–´ì•¼", "ì—†ìŒ", "ì—†ë‹¤", "ë•Œë¬¸", "ë•Œë¬¸ì—", "í•˜ì—¬", "í•˜ì—¬ì•¼", "í•˜ì˜€ë‹¤"]

# ğŸ”¹ **ì¤‘ìš” ì¡°ì‚¬ëŠ” ìœ ì§€ (ë¬¸ì¥ êµ¬ì¡° ê°œì„ )**
essential_josa = ["ì´", "ê°€", "ì€", "ëŠ”", "ì—", "ì„", "ë¥¼"]

def preprocessing(text, remove_stopwords=True):
    """
    âœ… ì‚¬ê³ ì›ì¸ ë° ì¬ë°œë°©ì§€ëŒ€ì±… ì „ì²˜ë¦¬ í•¨ìˆ˜ (Okt ê¸°ë°˜)
    - íŠ¹ìˆ˜ê¸°í˜¸, ìˆ«ì ì œê±°
    - í˜•íƒœì†Œ ë¶„ì„ í›„ í‘œì œì–´ ì¶”ì¶œ
    - ë¶ˆìš©ì–´ ë° í•„ìš” ì—†ëŠ” ì¡°ì‚¬ ì œê±° í›„ ë¬¸ì¥ ë³µì›
    """
    if not isinstance(text, str):  # ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš° ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
        return ""

    # 1ï¸âƒ£ **í•œê¸€ + ê³µë°± ì œì™¸í•œ ë¬¸ì(ìˆ«ì, íŠ¹ìˆ˜ê¸°í˜¸, ì˜ì–´) ì œê±°**
    text = re.sub(r"[^ê°€-í£\s]", "", text)

    # 2ï¸âƒ£ **í˜•íƒœì†Œ ë¶„ì„ ë° í‘œì œì–´ ì¶”ì¶œ**
    words = okt.pos(text, stem=True)  # í’ˆì‚¬ íƒœê¹… ì§„í–‰

    # 3ï¸âƒ£ **ë¶ˆìš©ì–´ ë° í•„ìš” ì—†ëŠ” ì¡°ì‚¬ ì œê±°**
    filtered_words = []
    for word, tag in words:
        if remove_stopwords and word in stop_words:
            continue
        if tag == "Josa" and word not in essential_josa:  # ì¤‘ìš”í•œ ì¡°ì‚¬ëŠ” ìœ ì§€
            continue
        filtered_words.append(word)

    # 4ï¸âƒ£ **ë¬¸ì¥ êµ¬ì¡°ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë³µì›**
    cleaned_text = " ".join(filtered_words)

    return cleaned_text
  
# ğŸ”¹ **ê²½ë¡œ ì„¤ì •**
script_dir = os.path.dirname(os.path.abspath(__file__))
train_path = os.path.join(script_dir, "..", "1.Data", "train.csv")
test_path = os.path.join(script_dir, "..", "1.Data", "test.csv")

# âœ… **(1) `train.csv`ì™€ `test.csv` ë¶ˆëŸ¬ì˜¤ê¸°**
train = pd.read_csv(train_path)
test = pd.read_csv(test_path)

# âœ… **(2) ë¶ˆí•„ìš”í•œ ì—´ ì‚­ì œ**
drop_columns = ["ë°œìƒì¼ì‹œ", "ì‚¬ê³ ì¸ì§€ ì‹œê°„", "ë‚ ì”¨", "ê¸°ì˜¨", "ìŠµë„", "ì—°ë©´ì ", "ì¸µ ì •ë³´", "ë¬¼ì ì‚¬ê³ ", "ë¶€ìœ„"]
train.drop(columns=drop_columns, inplace=True)
test.drop(columns=drop_columns, inplace=True)

# âœ… **(3) `ê³µì‚¬ì¢…ë¥˜`, `ê³µì¢…`, `ì‚¬ê³ ê°ì²´`ë¥¼ ëŒ€ë¶„ë¥˜/ì¤‘ë¶„ë¥˜ë¡œ ë‚˜ëˆ„ê¸°**
def split_columns(df): 
    df['ê³µì¢…(ì¤‘ë¶„ë¥˜)'] = df['ê³µì¢…'].str.split(' > ').str[1]
    df['ì‚¬ê³ ê°ì²´(ëŒ€ë¶„ë¥˜)'] = df['ì‚¬ê³ ê°ì²´'].str.split(' > ').str[0]
    df['ì‚¬ê³ ê°ì²´(ì¤‘ë¶„ë¥˜)'] = df['ì‚¬ê³ ê°ì²´'].str.split(' > ').str[1]
    df['ì¸ì ì‚¬ê³ (ëŒ€ë¶„ë¥˜)'] = df['ì¸ì ì‚¬ê³ '].str.split('(').str[0].str.strip()
    df['ì¸ì ì‚¬ê³ (ì¤‘ë¶„ë¥˜)'] = df['ì¸ì ì‚¬ê³ '].str.split('(').str[1].str.replace(')', '').str.strip()

split_columns(train)
split_columns(test)

# âœ… **(4) ì‚¬ê³ ì›ì¸ & ì¬ë°œë°©ì§€ëŒ€ì±… ì „ì²˜ë¦¬**
train["ì‚¬ê³ ì›ì¸_ì •ì œ"] = train["ì‚¬ê³ ì›ì¸"].apply(lambda x: preprocessing(x, remove_stopwords=True))
train["ì¬ë°œë°©ì§€ëŒ€ì±…_ì •ì œ"] = train["ì¬ë°œë°©ì§€ëŒ€ì±… ë° í–¥í›„ì¡°ì¹˜ê³„íš"].apply(lambda x: preprocessing(x, remove_stopwords=True))
test["ì‚¬ê³ ì›ì¸_ì •ì œ"] = test["ì‚¬ê³ ì›ì¸"].apply(lambda x: preprocessing(x, remove_stopwords=True))

# âœ… **(5) í›ˆë ¨ ë°ì´í„° í†µí•© ìƒì„±**
# í›ˆë ¨ ë°ì´í„° í†µí•© ìƒì„±
combined_training_data = train.apply(
    lambda row: {
        "question": (  
            f"ê³µì¢… ì¤‘ë¶„ë¥˜ '{row['ê³µì¢…(ì¤‘ë¶„ë¥˜)']}' ì‘ì—…ì—ì„œ "
            f"ì¸ì ì‚¬ê³  ëŒ€ë¶„ë¥˜ '{row['ì¸ì ì‚¬ê³ (ëŒ€ë¶„ë¥˜)']}', ì¤‘ë¶„ë¥˜ '{row['ì¸ì ì‚¬ê³ (ì¤‘ë¶„ë¥˜)']}' "
            f"ì‚¬ê³ ê°ì²´ '{row['ì‚¬ê³ ê°ì²´(ëŒ€ë¶„ë¥˜)']}'(ì¤‘ë¶„ë¥˜: '{row['ì‚¬ê³ ê°ì²´(ì¤‘ë¶„ë¥˜)']}')ì™€ ê´€ë ¨ëœ ì‚¬ê³ ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. "
            f"ì‘ì—… í”„ë¡œì„¸ìŠ¤ëŠ” '{row['ì‘ì—…í”„ë¡œì„¸ìŠ¤']}'ì´ë©°, ì‚¬ê³  ì›ì¸ì€ '{row['ì‚¬ê³ ì›ì¸']}'ì…ë‹ˆë‹¤. "
            f"ì¬ë°œ ë°©ì§€ ëŒ€ì±… ë° í–¥í›„ ì¡°ì¹˜ ê³„íšì€ ë¬´ì—‡ì¸ê°€ìš”?"
        ),
        "answer": row["ì¬ë°œë°©ì§€ëŒ€ì±… ë° í–¥í›„ì¡°ì¹˜ê³„íš"]
    },
    axis=1
)
# DataFrameìœ¼ë¡œ ë³€í™˜
combined_training_data = pd.DataFrame(list(combined_training_data))


# í…ŒìŠ¤íŠ¸ ë°ì´í„° í†µí•© ìƒì„±
combined_test_data = test.apply(
    lambda row: {
        "question": (
            f"ê³µì¢… ì¤‘ë¶„ë¥˜ '{row['ê³µì¢…(ì¤‘ë¶„ë¥˜)']}' ì‘ì—…ì—ì„œ "
            f"ì¸ì ì‚¬ê³  ëŒ€ë¶„ë¥˜ '{row['ì¸ì ì‚¬ê³ (ëŒ€ë¶„ë¥˜)']}', ì¤‘ë¶„ë¥˜ '{row['ì¸ì ì‚¬ê³ (ì¤‘ë¶„ë¥˜)']}' "
            f"ì‚¬ê³ ê°ì²´ '{row['ì‚¬ê³ ê°ì²´(ëŒ€ë¶„ë¥˜)']}'(ì¤‘ë¶„ë¥˜: '{row['ì‚¬ê³ ê°ì²´(ì¤‘ë¶„ë¥˜)']}')ì™€ ê´€ë ¨ëœ ì‚¬ê³ ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. "
            f"ì‘ì—… í”„ë¡œì„¸ìŠ¤ëŠ” '{row['ì‘ì—…í”„ë¡œì„¸ìŠ¤']}'ì´ë©°, ì‚¬ê³  ì›ì¸ì€ '{row['ì‚¬ê³ ì›ì¸']}'ì…ë‹ˆë‹¤. "
            f"ì¬ë°œ ë°©ì§€ ëŒ€ì±… ë° í–¥í›„ ì¡°ì¹˜ ê³„íšì€ ë¬´ì—‡ì¸ê°€ìš”?"
        )
    },
    axis=1
)

# DataFrameìœ¼ë¡œ ë³€í™˜
combined_test_data = pd.DataFrame(list(combined_test_data))


# âœ… **(8) ì €ì¥**
train_cleaned_path = os.path.join(script_dir, "..", "1.Data", "train_cleaned.csv")
test_cleaned_path = os.path.join(script_dir, "..", "1.Data", "test_cleaned.csv")

combined_training_data.to_csv(train_cleaned_path, index=False, encoding="utf-8-sig")
combined_test_data.to_csv(test_cleaned_path, index=False, encoding="utf-8-sig")

print(f"\nâœ… ì „ì²˜ë¦¬ ì™„ë£Œ! ì €ì¥ëœ íŒŒì¼: {train_cleaned_path}, {test_cleaned_path} ğŸš€")






